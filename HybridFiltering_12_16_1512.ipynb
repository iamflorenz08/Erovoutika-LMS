{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamflorenz08/Erovoutika-LMS/blob/main/HybridFiltering_12_16_1512.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A019yGfUyA9",
        "outputId": "c56d8e3c-f4dc-42cb-84f4-6df68c2ff2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/316.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/316.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m307.2/316.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.2.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=808328 sha256=f85ac680bbefcf47b737307bd4fdd4495af022bbb9238d488ffb3e646f51982b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.3)\n",
            "Installing collected packages: flask_ngrok\n",
            "Successfully installed flask_ngrok-0.0.25\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15963 sha256=bbe08c9a6a8235962909219f789c6e50a6d1e3a3c67166779b7e7f185dada30b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install lightfm\n",
        "!pip install flask_ngrok\n",
        "!pip install pyngrok==4.1.1\n",
        "!ngrok authtoken 2ZfIgpyBRspxkmpvlT7DIBUaJJL_K6q9YWd5cxCGy3NBowBd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE3riPYtVJ_n"
      },
      "outputs": [],
      "source": [
        "################################################\n",
        "# Importing necessary library\n",
        "################################################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# all lightfm imports\n",
        "from lightfm.data import Dataset\n",
        "from lightfm import LightFM\n",
        "from lightfm import cross_validation\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from lightfm.evaluation import auc_score\n",
        "from lightfm.evaluation import recall_at_k\n",
        "from lightfm.evaluation import reciprocal_rank\n",
        "\n",
        "# imports re for text cleaning\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se03b2xZVRCq"
      },
      "source": [
        "**Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZui6WwAVTnr"
      },
      "outputs": [],
      "source": [
        "df_topics = pd.read_csv('/content/drive/MyDrive/Datasets/back_up_topics.csv')\n",
        "df_users = pd.read_csv('/content/drive/MyDrive/Datasets/users.csv')\n",
        "df_views = pd.read_csv('/content/drive/MyDrive/Datasets/back_up_views.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdiCECO_CNHy"
      },
      "outputs": [],
      "source": [
        "df_views = df_views.drop(['Unnamed: 0'],axis=1)\n",
        "tags_columns = df_topics.filter(like='tags')\n",
        "df_topics['tags'] = tags_columns.apply(lambda row: ','.join(filter(lambda x: pd.notna(x), row)), axis=1)\n",
        "df_topics = df_topics[['_id', 'author', 'title', 'tags']]\n",
        "df_users = df_users.rename(columns={'Tags': 'tags'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eGhJhuSVfzn"
      },
      "outputs": [],
      "source": [
        "df_topics['tags'] = df_topics['tags'].str.replace('<', '')\n",
        "df_topics['tags']  = df_topics['tags'].str.replace('>', ' ')\n",
        "df_topics['tags']  = df_topics['tags'].str.strip()\n",
        "df_topics['tags']  = df_topics['tags'].str.replace(' ', ',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "zHm1LrxY-OSO",
        "outputId": "bdca5092-db05-482a-8d73-5cd0f8ee734a"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Tags'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f59fe678fa10>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0musers_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mtopics_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Tags'"
          ]
        }
      ],
      "source": [
        "def biased_random_choice(biased_num):\n",
        "    random_number = random.random()\n",
        "    if random_number < biased_num:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "user_num = []\n",
        "question_num = []\n",
        "topics_tags = []\n",
        "users_tags = []\n",
        "\n",
        "for tags in df_topics['Tags']:\n",
        "  topics_tags.append(tags)\n",
        "\n",
        "for tags in df_users['Tags']:\n",
        "  users_tags.append(tags.split(','))\n",
        "\n",
        "for i in range(6):\n",
        "  for index, topic_tags in enumerate(topics_tags):\n",
        "    if(biased_random_choice(0.05)):\n",
        "      user_num.append(i)\n",
        "      question_num.append(index)\n",
        "      continue\n",
        "    else:\n",
        "      if(biased_random_choice(0.3)):\n",
        "        for user_tag in users_tags[i]:\n",
        "          if user_tag in topic_tags:\n",
        "            user_num.append(i)\n",
        "            question_num.append(index)\n",
        "            break\n",
        "\n",
        "df_views_ = pd.DataFrame()\n",
        "df_views_['user_num'] = user_num\n",
        "df_views_['question_num'] = question_num\n",
        "\n",
        "df_views = df_views_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS6e8VawZ7J4"
      },
      "outputs": [],
      "source": [
        "def generate_int_id(dataframe, id_col_name):\n",
        "    \"\"\"\n",
        "    Generate unique integer id for users, questions and answers\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe: Dataframe\n",
        "        Pandas Dataframe for Users or Q&A.\n",
        "    id_col_name : String\n",
        "        New integer id's column name.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dataframe\n",
        "        Updated dataframe containing new id column\n",
        "    \"\"\"\n",
        "    new_dataframe=dataframe.assign(\n",
        "        int_id_col_name=np.arange(len(dataframe))\n",
        "        ).reset_index(drop=True)\n",
        "    return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
        "\n",
        "\n",
        "\n",
        "def create_features(dataframe, features_name, id_col_name):\n",
        "    \"\"\"\n",
        "    Generate features that will be ready for feeding into lightfm\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe: Dataframe\n",
        "        Pandas Dataframe which contains features\n",
        "    features_name : List\n",
        "        List of feature columns name avaiable in dataframe\n",
        "    id_col_name: String\n",
        "        Column name which contains id of the question or\n",
        "        answer that the features will map to.\n",
        "        There are two possible values for this variable.\n",
        "        1. questions_id_num\n",
        "        2. professionals_id_num\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Pandas Series\n",
        "        A pandas series containing process features\n",
        "        that are ready for feed into lightfm.\n",
        "        The format of each value\n",
        "        will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
        "        Ex. -> (1, ['military', 'army', '5'])\n",
        "    \"\"\"\n",
        "\n",
        "    features = dataframe[features_name].apply(\n",
        "        lambda x: ','.join(x.map(str)), axis=1)\n",
        "    features = features.str.split(',')\n",
        "    features = list(zip(dataframe[id_col_name], features))\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "def generate_feature_list(dataframe, features_name):\n",
        "    \"\"\"\n",
        "    Generate features list for mapping\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe: Dataframe\n",
        "        Pandas Dataframe for Users or Q&A.\n",
        "    features_name : List\n",
        "        List of feature columns name avaiable in dataframe.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List of all features for mapping\n",
        "    \"\"\"\n",
        "    features = dataframe[features_name].apply(\n",
        "        lambda x: ','.join(x.map(str)), axis=1)\n",
        "    features = features.str.split(',')\n",
        "    features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
        "    return features\n",
        "\n",
        "\n",
        "def calculate_auc_score(lightfm_model, interactions_matrix,\n",
        "                        question_features, professional_features):\n",
        "    \"\"\"\n",
        "    Measure the ROC AUC metric for a model.\n",
        "    A perfect score is 1.0.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lightfm_model: LightFM model\n",
        "        A fitted lightfm model\n",
        "    interactions_matrix :\n",
        "        A lightfm interactions matrix\n",
        "    question_features, professional_features:\n",
        "        Lightfm features\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    String containing AUC score\n",
        "    \"\"\"\n",
        "    score = auc_score(\n",
        "        lightfm_model, interactions_matrix,\n",
        "        item_features=question_features,\n",
        "        user_features=professional_features,\n",
        "        num_threads=4).mean()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDcYp0dddDx1"
      },
      "outputs": [],
      "source": [
        "# generating unique integer id for users and q&a\n",
        "df_users = generate_int_id(df_users, 'users_id_num')\n",
        "df_topics = generate_int_id(df_topics, 'topics_id_num')\n",
        "df_views = generate_int_id(df_views, 'views_id_num')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqHT8btgjw_u"
      },
      "outputs": [],
      "source": [
        "df_users = df_users.rename(columns={'tags': 'user_tags'})\n",
        "df_topics = df_topics.rename(columns={'tags': 'topic_tags'})\n",
        "df_views = df_views.rename(columns={'user_num': 'user_id'})\n",
        "df_views = df_views.rename(columns={'question_num': 'topic_id'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc7O3kJ0gxjV"
      },
      "outputs": [],
      "source": [
        "df_merge = df_views.merge(\n",
        "    df_users, how='left',\n",
        "    left_on='user_id', right_on='users_id_num')\n",
        "df_merge = df_merge.merge(\n",
        "    df_topics, how='left',\n",
        "    left_on='topic_id', right_on='topics_id_num')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRjmeIvnlvkV"
      },
      "outputs": [],
      "source": [
        "viewed_topics_tags = df_merge[['UserId', 'topic_tags']]\n",
        "\n",
        "viewed_topics_tags = viewed_topics_tags.groupby(\n",
        "    ['UserId'])['topic_tags'].apply(\n",
        "        ','.join).reset_index()\n",
        "\n",
        "viewed_topics_tags['topic_tags'] = (\n",
        "    viewed_topics_tags['topic_tags'].str.split(',').apply(set).str.join(','))\n",
        "\n",
        "df_users = df_users.merge(viewed_topics_tags, how='left', on='UserId')\n",
        "\n",
        "df_users['user_all_tags'] = (\n",
        "    df_users[['user_tags', 'topic_tags']].apply(\n",
        "        lambda x: ','.join(x.dropna()),\n",
        "        axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWhQb6Ugo9b0"
      },
      "outputs": [],
      "source": [
        "df_topics['topic_tags'] = df_topics['topic_tags'].str.split(',').apply(set).str.join(',')\n",
        "df_users['user_all_tags'] = df_users['user_all_tags'].fillna('No Tag')\n",
        "df_users['user_all_tags'] = df_users['user_all_tags'].replace('', 'No Tag')\n",
        "df_users['user_all_tags'] = df_users['user_all_tags'].str.split(',').apply(set).str.join(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhxattzlntSg"
      },
      "outputs": [],
      "source": [
        "# generating features list for mapping\n",
        "topic_feature_list = generate_feature_list(\n",
        "    df_topics,\n",
        "    ['topic_tags'])\n",
        "\n",
        "user_feature_list = generate_feature_list(\n",
        "    df_users,\n",
        "    ['user_all_tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8_9JgeZrF6C"
      },
      "outputs": [],
      "source": [
        "# creating features for feeding into lightfm\n",
        "df_topics['topic_features'] = create_features(\n",
        "    df_topics, ['topic_tags'],\n",
        "    'topics_id_num')\n",
        "\n",
        "df_users['user_features'] = create_features(\n",
        "    df_users,\n",
        "    ['user_all_tags'],\n",
        "    'users_id_num')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zImbrvKCtC2u"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# Dataset building for lightfm\n",
        "########################\n",
        "\n",
        "# define our dataset variable\n",
        "# then we feed unique professionals and questions ids\n",
        "# and item and professional feature list\n",
        "# this will create lightfm internel mapping\n",
        "dataset = Dataset()\n",
        "dataset.fit(\n",
        "    set(df_users['users_id_num']),\n",
        "    set(df_topics['topics_id_num']),\n",
        "    item_features=topic_feature_list,\n",
        "    user_features=user_feature_list)\n",
        "\n",
        "\n",
        "# now we are building interactions matrix between professionals and quesitons\n",
        "# we are passing professional and questions id as a tuple\n",
        "# e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
        "# then we use lightfm build in method for building interactions matrix\n",
        "df_merge['user_topic_tuple'] = list(zip(\n",
        "    df_merge.users_id_num, df_merge.topics_id_num))\n",
        "\n",
        "interactions, weights = dataset.build_interactions(\n",
        "    df_merge['user_topic_tuple'])\n",
        "\n",
        "train_interaction, test_interaction = cross_validation.random_train_test_split(interactions, 0.3, np.random.RandomState(2019))\n",
        "train_weights, test_weights = cross_validation.random_train_test_split(interactions, 0.3, np.random.RandomState(2019))\n",
        "\n",
        "# now we are building our questions and professionals features\n",
        "# in a way that lightfm understand.\n",
        "# we are using lightfm build in method for building\n",
        "# questions and professionals features\n",
        "topic_features = dataset.build_item_features(\n",
        "    df_topics['topic_features'])\n",
        "\n",
        "user_features = dataset.build_user_features(\n",
        "    df_users['user_features'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWcbZRlBuES6",
        "outputId": "a064708e-a97d-4391-efbf-4ba9f7c51e17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 45/45 [00:01<00:00, 22.77it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7b813bf2f700>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "################################\n",
        "# Model building part\n",
        "################################\n",
        "\n",
        "# define lightfm model by specifying hyper-parametre\n",
        "# then fit the model with ineteractions matrix, item and user features\n",
        "model = LightFM(\n",
        "    no_components=350,\n",
        "    learning_rate=0.1,\n",
        "    loss='warp',\n",
        "    k=15,\n",
        "    random_state=2019)\n",
        "\n",
        "model.fit(\n",
        "    interactions,\n",
        "    item_features=topic_features,\n",
        "    user_features=user_features,\n",
        "    sample_weight=interactions,\n",
        "    epochs=45, num_threads=4, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDkdJ4yccMVN",
        "outputId": "3dad6bd8-6762-4ec9-eabf-919b8b67e3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC Score 0.9951532\n",
            "Precision at 15 Score 0.8777778\n",
            "Recall at 15 Score 0.8007725682129854\n",
            "Reciprocal rank Score 0.8888889\n"
          ]
        }
      ],
      "source": [
        "print('AUC Score', auc_score(model, interactions, user_features=user_features, item_features=topic_features).mean())\n",
        "print('Precision at 15 Score',precision_at_k(model, interactions,user_features=user_features, item_features=topic_features, k=15).mean())\n",
        "print('Recall at 15 Score',recall_at_k(model, interactions,user_features=user_features, item_features=topic_features, k=15).mean())\n",
        "print('Reciprocal rank Score',reciprocal_rank(model, interactions,user_features=user_features, item_features=topic_features).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BksalRHUuSlL"
      },
      "outputs": [],
      "source": [
        "def predict(user_id, items_per_page=10):\n",
        "  matching_indices = df_users.loc[df_users['UserId'].str.strip() == user_id].index\n",
        "  user_index = int(matching_indices[0])\n",
        "\n",
        "  previous_topic_id_num = df_merge.loc[df_merge['users_id_num'] == user_index][:10]['topics_id_num']\n",
        "  df_previous_topics = df_topics.loc[df_topics['topics_id_num'].isin(previous_topic_id_num)]\n",
        "\n",
        "  discard_topic_id = df_previous_topics['topics_id_num'].values.tolist()\n",
        "  df_use_for_prediction = df_topics.loc[~df_topics['topics_id_num'].isin(discard_topic_id)]\n",
        "  questions_id_for_predict = df_use_for_prediction['topics_id_num'].values.tolist()\n",
        "\n",
        "  scores = model.predict(\n",
        "              user_index,\n",
        "              questions_id_for_predict,\n",
        "              item_features=topic_features,\n",
        "              user_features=user_features)\n",
        "\n",
        "  df_use_for_prediction['scores'] = scores\n",
        "  df_use_for_prediction = df_use_for_prediction.sort_values(by='scores', ascending=False)[:items_per_page]\n",
        "  return df_use_for_prediction['_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOId8Cg_TOUC",
        "outputId": "f74dcf84-32f0-4f0d-e598-5e13bbe87f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://f93f-34-82-131-196.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [19/Dec/2023 03:03:05] \"GET /recommend/656d5d64a6dc8e108c76a5c9?per_page=30 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Dec/2023 03:03:05] \"GET /recommend/656d5d64a6dc8e108c76a5c9?per_page=30 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Dec/2023 03:04:35] \"GET /recommend/656d5d64a6dc8e108c76a5c9?per_page=30 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Dec/2023 03:07:16] \"GET /recommend/657be5917bf6fa0cb36a2adb?per_page=30 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Dec/2023 03:09:23] \"GET /recommend/657be5917bf6fa0cb36a2adb?per_page=30 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Dec/2023 03:29:42] \"GET /recommend/656d5d64a6dc8e108c76a5c9?per_page=30 HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/recommend/<string:user_id>\")\n",
        "def home(user_id):\n",
        "    per_page = int(request.args.get('per_page', 10))\n",
        "    return jsonify(predict(user_id, per_page).to_numpy().tolist())\n",
        "\n",
        "\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yGd4UJ3BWnfShu_1XnbqFsbp_Ez-sveB",
      "authorship_tag": "ABX9TyPOhlM2qC3FEmbC3f9DDYPs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}